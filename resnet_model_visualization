digraph {
	graph [size="43.5,43.5"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2076743323872 [label="
 (1, 1, 224, 224)" fillcolor=darkolivegreen1]
	2074620690096 [label=ConvolutionBackward0]
	2074620677184 -> 2074620690096
	2074620677184 [label=AddBackward0]
	2074620680208 -> 2074620677184
	2074620680208 [label=ReluBackward0]
	2074620678384 -> 2074620680208
	2074620678384 [label=AddBackward0]
	2074620687360 -> 2074620678384
	2074620687360 [label=ConvolutionBackward0]
	2074620686400 -> 2074620687360
	2074620686400 [label=ReluBackward0]
	2074620685536 -> 2074620686400
	2074620685536 [label=ConvolutionBackward0]
	2074620687456 -> 2074620685536
	2074620687456 [label=ReluBackward0]
	2074620676848 -> 2074620687456
	2074620676848 [label=ConvolutionBackward0]
	2074620684624 -> 2074620676848
	2074620684624 [label=AddBackward0]
	2074620675648 -> 2074620684624
	2074620675648 [label=ReluBackward0]
	2074620675504 -> 2074620675648
	2074620675504 [label=AddBackward0]
	2074620675456 -> 2074620675504
	2074620675456 [label=ConvolutionBackward0]
	2074620674928 -> 2074620675456
	2074620674928 [label=ReluBackward0]
	2074620682320 -> 2074620674928
	2074620682320 [label=ConvolutionBackward0]
	2074620675312 -> 2074620682320
	2074620675312 [label=ReluBackward0]
	2074620687024 -> 2074620675312
	2074620687024 [label=ConvolutionBackward0]
	2074620677328 -> 2074620687024
	2074620677328 [label=AddBackward0]
	2074620676512 -> 2074620677328
	2074620676512 [label=ReluBackward0]
	2074620675744 -> 2074620676512
	2074620675744 [label=AddBackward0]
	2074620676176 -> 2074620675744
	2074620676176 [label=ConvolutionBackward0]
	2074620682512 -> 2074620676176
	2074620682512 [label=ReluBackward0]
	2074620680400 -> 2074620682512
	2074620680400 [label=ConvolutionBackward0]
	2074620686976 -> 2074620680400
	2074620686976 [label=ReluBackward0]
	2074620894736 -> 2074620686976
	2074620894736 [label=ConvolutionBackward0]
	2074620894160 -> 2074620894736
	2074620894160 [label=ReluBackward0]
	2074620901264 -> 2074620894160
	2074620901264 [label=AddBackward0]
	2074620901024 -> 2074620901264
	2074620901024 [label=ConvolutionBackward0]
	2074620900688 -> 2074620901024
	2074620900688 [label=ReluBackward0]
	2074620899728 -> 2074620900688
	2074620899728 [label=ConvolutionBackward0]
	2074620891472 -> 2074620899728
	2074620891472 [label=MaxPool2DWithIndicesBackward0]
	2074620675264 -> 2074620891472
	2074620675264 [label=ReluBackward0]
	2074620898960 -> 2074620675264
	2074620898960 [label=AddBackward0]
	2074620889984 -> 2074620898960
	2074620889984 [label=ConvolutionBackward0]
	2074620897424 -> 2074620889984
	2074620897424 [label=ReluBackward0]
	2074620888688 -> 2074620897424
	2074620888688 [label=ConvolutionBackward0]
	2074620896464 -> 2074620888688
	2074620896464 [label=MaxPool2DWithIndicesBackward0]
	2074620675600 -> 2074620896464
	2074620675600 [label=ReluBackward0]
	2074620887920 -> 2074620675600
	2074620887920 [label=AddBackward0]
	2074620895600 -> 2074620887920
	2074620895600 [label=ConvolutionBackward0]
	2074620893008 -> 2074620895600
	2074620893008 [label=ReluBackward0]
	2074620888544 -> 2074620893008
	2074620888544 [label=ConvolutionBackward0]
	2074620900544 -> 2074620888544
	2074620900544 [label=MaxPool2DWithIndicesBackward0]
	2074620689424 -> 2074620900544
	2074620689424 [label=ReluBackward0]
	2074620903232 -> 2074620689424
	2074620903232 [label=AddBackward0]
	2074620893200 -> 2074620903232
	2074620893200 [label=ConvolutionBackward0]
	2074620888736 -> 2074620893200
	2074620888736 [label=ReluBackward0]
	2074620899200 -> 2074620888736
	2074620899200 [label=ConvolutionBackward0]
	2074620888064 -> 2074620899200
	2076762764256 [label="encoder1.conv1.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	2076762764256 -> 2074620888064
	2074620888064 [label=AccumulateGrad]
	2074620898288 -> 2074620899200
	2076762759856 [label="encoder1.conv1.bias
 (64)" fillcolor=lightblue]
	2076762759856 -> 2074620898288
	2074620898288 [label=AccumulateGrad]
	2074620891664 -> 2074620893200
	2076762761296 [label="encoder1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2076762761296 -> 2074620891664
	2074620891664 [label=AccumulateGrad]
	2074620890320 -> 2074620893200
	2076762760976 [label="encoder1.conv2.bias
 (64)" fillcolor=lightblue]
	2076762760976 -> 2074620890320
	2074620890320 [label=AccumulateGrad]
	2074620889408 -> 2074620903232
	2074620889408 [label=ConvolutionBackward0]
	2074620893920 -> 2074620889408
	2076762760496 [label="encoder1.skip.weight
 (64, 1, 1, 1)" fillcolor=lightblue]
	2076762760496 -> 2074620893920
	2074620893920 [label=AccumulateGrad]
	2074620894112 -> 2074620889408
	2076762767056 [label="encoder1.skip.bias
 (64)" fillcolor=lightblue]
	2076762767056 -> 2074620894112
	2074620894112 [label=AccumulateGrad]
	2074620903136 -> 2074620888544
	2076762758256 [label="encoder2.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2076762758256 -> 2074620903136
	2074620903136 [label=AccumulateGrad]
	2074620901744 -> 2074620888544
	2076762758096 [label="encoder2.conv1.bias
 (128)" fillcolor=lightblue]
	2076762758096 -> 2074620901744
	2074620901744 [label=AccumulateGrad]
	2074620893584 -> 2074620895600
	2076762757456 [label="encoder2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2076762757456 -> 2074620893584
	2074620893584 [label=AccumulateGrad]
	2074620895264 -> 2074620895600
	2074621771936 [label="encoder2.conv2.bias
 (128)" fillcolor=lightblue]
	2074621771936 -> 2074620895264
	2074620895264 [label=AccumulateGrad]
	2074620887344 -> 2074620887920
	2074620887344 [label=ConvolutionBackward0]
	2074620900544 -> 2074620887344
	2074620888640 -> 2074620887344
	2076762661712 [label="encoder2.skip.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2076762661712 -> 2074620888640
	2074620888640 [label=AccumulateGrad]
	2074620897184 -> 2074620887344
	2076762660672 [label="encoder2.skip.bias
 (128)" fillcolor=lightblue]
	2076762660672 -> 2074620897184
	2074620897184 [label=AccumulateGrad]
	2074620888256 -> 2074620888688
	2076762661632 [label="encoder3.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2076762661632 -> 2074620888256
	2074620888256 [label=AccumulateGrad]
	2074620897088 -> 2074620888688
	2076762660992 [label="encoder3.conv1.bias
 (256)" fillcolor=lightblue]
	2076762660992 -> 2074620897088
	2074620897088 [label=AccumulateGrad]
	2074620889168 -> 2074620889984
	2076762661952 [label="encoder3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2076762661952 -> 2074620889168
	2074620889168 [label=AccumulateGrad]
	2074620897568 -> 2074620889984
	2076762661792 [label="encoder3.conv2.bias
 (256)" fillcolor=lightblue]
	2076762661792 -> 2074620897568
	2074620897568 [label=AccumulateGrad]
	2074620898000 -> 2074620898960
	2074620898000 [label=ConvolutionBackward0]
	2074620896464 -> 2074620898000
	2074620888400 -> 2074620898000
	2076762660192 [label="encoder3.skip.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2076762660192 -> 2074620888400
	2074620888400 [label=AccumulateGrad]
	2074620887728 -> 2074620898000
	2076762660272 [label="encoder3.skip.bias
 (256)" fillcolor=lightblue]
	2076762660272 -> 2074620887728
	2074620887728 [label=AccumulateGrad]
	2074620899632 -> 2074620899728
	2076762662032 [label="bottleneck.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2076762662032 -> 2074620899632
	2074620899632 [label=AccumulateGrad]
	2074620892048 -> 2074620899728
	2076762660352 [label="bottleneck.conv1.bias
 (512)" fillcolor=lightblue]
	2076762660352 -> 2074620892048
	2074620892048 [label=AccumulateGrad]
	2074620892336 -> 2074620901024
	2076762660592 [label="bottleneck.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2076762660592 -> 2074620892336
	2074620892336 [label=AccumulateGrad]
	2074620900784 -> 2074620901024
	2076762661072 [label="bottleneck.conv2.bias
 (512)" fillcolor=lightblue]
	2076762661072 -> 2074620900784
	2074620900784 [label=AccumulateGrad]
	2074620900832 -> 2074620901264
	2074620900832 [label=ConvolutionBackward0]
	2074620891472 -> 2074620900832
	2074620899680 -> 2074620900832
	2076762661232 [label="bottleneck.skip.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2076762661232 -> 2074620899680
	2074620899680 [label=AccumulateGrad]
	2074620898912 -> 2074620900832
	2076762661312 [label="bottleneck.skip.bias
 (512)" fillcolor=lightblue]
	2076762661312 -> 2074620898912
	2074620898912 [label=AccumulateGrad]
	2074620902272 -> 2074620894736
	2076762659392 [label="decoder3.0.weight
 (512, 256, 2, 2)" fillcolor=lightblue]
	2076762659392 -> 2074620902272
	2074620902272 [label=AccumulateGrad]
	2074620894832 -> 2074620894736
	2076762659472 [label="decoder3.0.bias
 (256)" fillcolor=lightblue]
	2076762659472 -> 2074620894832
	2074620894832 [label=AccumulateGrad]
	2074620903280 -> 2074620680400
	2076762659632 [label="decoder3.2.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2076762659632 -> 2074620903280
	2074620903280 [label=AccumulateGrad]
	2074620895024 -> 2074620680400
	2076762658912 [label="decoder3.2.conv1.bias
 (256)" fillcolor=lightblue]
	2076762658912 -> 2074620895024
	2074620895024 [label=AccumulateGrad]
	2074620679872 -> 2074620676176
	2076762659072 [label="decoder3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2076762659072 -> 2074620679872
	2074620679872 [label=AccumulateGrad]
	2074620689328 -> 2074620676176
	2076762659152 [label="decoder3.2.conv2.bias
 (256)" fillcolor=lightblue]
	2076762659152 -> 2074620689328
	2074620689328 [label=AccumulateGrad]
	2074620686976 -> 2074620675744
	2074620675264 -> 2074620677328
	2074620687552 -> 2074620687024
	2076762658832 [label="decoder2.0.weight
 (256, 128, 2, 2)" fillcolor=lightblue]
	2076762658832 -> 2074620687552
	2074620687552 [label=AccumulateGrad]
	2074620690000 -> 2074620687024
	2076762655792 [label="decoder2.0.bias
 (128)" fillcolor=lightblue]
	2076762655792 -> 2074620690000
	2074620690000 [label=AccumulateGrad]
	2074620687168 -> 2074620682320
	2076762658752 [label="decoder2.2.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2076762658752 -> 2074620687168
	2074620687168 [label=AccumulateGrad]
	2074620679968 -> 2074620682320
	2076762658512 [label="decoder2.2.conv1.bias
 (128)" fillcolor=lightblue]
	2076762658512 -> 2074620679968
	2074620679968 [label=AccumulateGrad]
	2074620674880 -> 2074620675456
	2076762658272 [label="decoder2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2076762658272 -> 2074620674880
	2074620674880 [label=AccumulateGrad]
	2074620675216 -> 2074620675456
	2076762658352 [label="decoder2.2.conv2.bias
 (128)" fillcolor=lightblue]
	2076762658352 -> 2074620675216
	2074620675216 [label=AccumulateGrad]
	2074620675312 -> 2074620675504
	2074620675600 -> 2074620684624
	2074620676320 -> 2074620676848
	2076762652832 [label="decoder1.0.weight
 (128, 64, 2, 2)" fillcolor=lightblue]
	2076762652832 -> 2074620676320
	2074620676320 [label=AccumulateGrad]
	2074620685200 -> 2074620676848
	2076762652992 [label="decoder1.0.bias
 (64)" fillcolor=lightblue]
	2076762652992 -> 2074620685200
	2074620685200 [label=AccumulateGrad]
	2074620677136 -> 2074620685536
	2076762653152 [label="decoder1.2.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2076762653152 -> 2074620677136
	2074620677136 [label=AccumulateGrad]
	2074620676992 -> 2074620685536
	2076762653232 [label="decoder1.2.conv1.bias
 (64)" fillcolor=lightblue]
	2076762653232 -> 2074620676992
	2074620676992 [label=AccumulateGrad]
	2074620677712 -> 2074620687360
	2069140103616 [label="decoder1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2069140103616 -> 2074620677712
	2074620677712 [label=AccumulateGrad]
	2074620687648 -> 2074620687360
	2069140104896 [label="decoder1.2.conv2.bias
 (64)" fillcolor=lightblue]
	2069140104896 -> 2074620687648
	2074620687648 [label=AccumulateGrad]
	2074620687456 -> 2074620678384
	2074620689424 -> 2074620677184
	2074620687840 -> 2074620690096
	2069139206016 [label="output.weight
 (1, 64, 1, 1)" fillcolor=lightblue]
	2069139206016 -> 2074620687840
	2074620687840 [label=AccumulateGrad]
	2074620688752 -> 2074620690096
	2069139199376 [label="output.bias
 (1)" fillcolor=lightblue]
	2069139199376 -> 2074620688752
	2074620688752 [label=AccumulateGrad]
	2074620690096 -> 2076743323872
}
